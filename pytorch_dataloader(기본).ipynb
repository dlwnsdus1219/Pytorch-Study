{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**파이토치 기본 제공 데이터 사용**\n"
      ],
      "metadata": {
        "id": "dQX6WZUzZyet"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DwKiKFe-Zrnj"
      },
      "outputs": [],
      "source": [
        "import torch # 파이토치 기본 라이브러리\n",
        "import torchvision # 이미지 관련 된 파이토치 라이브러리\n",
        "import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n",
        "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
        "import numpy as np # 넘파이 기본 라이브러리\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transf = tr.Compose([tr.Resize(16), tr.ToTensor()])    # 16*16으로 이미지 타입 변환 후 텐서 타입으로 변환!!\n",
        "\n",
        "# torchvision.datasets에서 기본 제공하는 CIFAR10 데이터 불러옴\n",
        "# root에는 다운로드 받을 경로를 입력한다.\n",
        "# train=Ture이면 학습 데이터를 불러오고 train=False이면 테스트 데이터를 불러온다.\n",
        "# 미리 선언한 전처리를 사용하기 위해 transform=transf을 입력한다.\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOQ9AbhDZ-1I",
        "outputId": "ebf2f8cf-fa9d-49a4-f90c-053d6d7e7510"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 58714203.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 데이터셋은 이미지, 라벨이 동시에 들어있는 튜플 형태이다!!\n",
        "\n",
        "trainset[0]: 1st 데이터 - 이미지 한장([0][0]) + 라벨 숫자 하나([0][1])"
      ],
      "metadata": {
        "id": "me4jPrMubeCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset[0][0].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_ydtTvkbaG9",
        "outputId": "c22a9635-cf62-486a-bb72-6787ba07624f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RGB: 너비 * 높이 * 채널 수\n",
        "\n",
        "파이토치: 채널 수 * 너비 * 높이"
      ],
      "metadata": {
        "id": "fz0H51KHcM7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader는 데이터를 미니 배치 형태로 만들어 준다.\n",
        "# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.\n",
        "trainloader = DataLoader(trainset, batch_size=50, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "l8cY40-ccDKF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A_wRiY8caeO",
        "outputId": "04de17b7-c450-46ff-dccc-cb39db8a1f12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iter, next를 이용해 일부 데이터를 확인할 수 있다.\n",
        "images, labels = next(iter(trainloader))\n",
        "print(images.size())\n",
        "# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.\n",
        "# (배치 크기)x(채널 수)x(너비)x(높이)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlw2Y-Ofcded",
        "outputId": "7b1be317-4c70-4cac-ff5f-b758f24db976"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 3, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://dacon.io/forum/407531\n",
        "\n",
        "\n",
        "\n",
        "_SingleProcessDataLoaderIter' object has no attribute 'next' 오류 해결\n",
        "\n"
      ],
      "metadata": {
        "id": "eT5b6Hz4dFV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그림 그리기 위해 채널 수를 가장 뒤로 보낸다\n",
        "oneshot = images[1].permute(1,2,0).numpy()\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(oneshot)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "IJt0AgrdjrC5",
        "outputId": "1b45d3d8-20f9-4345-fccc-aa4bb026cc54"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**같은 클래스 별로 폴더를 정리한 경우**\n",
        "\n",
        "--> ImageFolder 하나로 개인 데이터 사용 가능!!\n",
        "\n",
        "별도의 라벨링 필요 X, 폴더 별 자동 라벨링!!"
      ],
      "metadata": {
        "id": "04e0CtiOkFtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content/drive/MyDrive/Pytorch_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpcIdOqzlv2t",
        "outputId": "95afbe75-4ae5-4e3b-f263-d4cafc56d2e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pytorch_sample\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transf = tr.Compose([tr.Resize(128), tr.ToTensor()])    # 128*128로 이미지 타입 변환 후 텐서 타입으로 변환!!\n",
        "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf) # 커스텀 데이터 불러온다.\n",
        "trainloader = DataLoader(trainset, batch_size=2, shuffle=False) # 데이터를 미니 배치 형태로 만들어 준다."
      ],
      "metadata": {
        "id": "GaC5tZRtkPLx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정리 안 된 커스텀 데이터 불러오기**"
      ],
      "metadata": {
        "id": "dK3unt0nl3K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 32*32 크기의 RGB 컬러 이미지 100장, 그에 대한 라벨이 넘파이 형태로 정리되어 있다고 치자\n",
        "\n",
        "train_images = np.random.randint(256,size=(100,32,32,3))/255 # (이미지 수)x(너비)x(높이)x(채널 수)\n",
        "train_labels = np.random.randint(2,size=(100,1)) # 라벨 수\n",
        "\n",
        "# 이미지 전처리 작업이 필요할 경우 openCV와 같은 라이브러리를 이용하여 이 곳에서 작업할 수도 있다.\n",
        "# 필자는 이 단계에서 전처리하는 것을 선호한다. 그 이유는 torchvision.transforms 라이브러리 보다\n",
        "# OpenCV, SciPy와 같은 라이브러리가 더 많은 전처리 기술을 제공하며 이미지를 미리 처리해 놓고 전처리 된 이미지를 살펴보면서\n",
        "# 작업하는 것을 좋아하기 때문이다. 따라서 사용 목적과 편의성에 맞게 본인이 전처리를 어디서 할 지 정하면 될 것이다."
      ],
      "metadata": {
        "id": "DqlQ1qxKlzsY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorData(Dataset):\n",
        "    def __init__(self, x_data, y_data):\n",
        "        self.x_data = torch.FloatTensor(x_data) # 이미지 데이터 to FloatTensor\n",
        "        self.x_data = self.x_data.permute(0,3,1,2)  # (이미지 수)x(너비)x(높이)x(채널 수) -> (배치 크기)x(채널 수)x(너비)x(높이)\n",
        "        self.y_data = torch.LongTensor(y_data)  # 라벨 데이터 to LongTensor\n",
        "        self.len = self.y_data.shape[0] # 클래스 내 들어온 데이터 개수\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index] # 뽑아 낼 데이터를 적어준다.\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len # 클래스 내의 들어 온 데이터 개수\n",
        "\n",
        "# 파이토치에서는 (배치 크기)x(채널 수)x(너비)x(높이) 데이터가 사용 되므로 원래 데이터 (이미지 수)x(너비)x(높이)x(채널 수)를 변경해야만 한다.\n",
        "# permute에서 0(이미지 수), 1(너비),2 (높이), 3(채널 수)을 0(이미지 수), 3(채널 수), 1(너비),2 (높이)로 바꿔주는 것이기 때문에\n",
        "# .permute(0,3,1,2)을 사용하는 것이다."
      ],
      "metadata": {
        "id": "irrlQFVGmuQ1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorData(train_images,train_labels) # 텐서 데이터 불러오기\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True) # 미니 배치 형태로 데이터 갖추기"
      ],
      "metadata": {
        "id": "bZvWSoZpn5Ll"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}