{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhhbiOx-upN9"
      },
      "source": [
        "# k겹 교차 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfzDDDGluuj5"
      },
      "source": [
        "- 학습 데이터 사용하면서 검증\n",
        "- 머신 러닝 분야에서 널리 쓰임!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzfu8D2SukKP",
        "outputId": "4c905cc1-413b-4bc5-95fa-b9400c064bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK0SJGC6vCj6",
        "outputId": "48384574-981e-45de-db02-f5e4d66ba2e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Pytorch_sample/data\n"
          ]
        }
      ],
      "source": [
        "cd /content/gdrive/MyDrive/Pytorch_sample/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rg1bFdAKvuqN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # 데이터프레임 형태를 다룰 수 있는 라이브러리\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split # 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n",
        "\n",
        "# ANN\n",
        "import torch\n",
        "from torch import nn, optim # torch 내의 세부적인 기능을 불러온다. (신경망 기술, 손실함수, 최적화 방법 등)\n",
        "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
        "import torch.nn.functional as F # torch 내의 세부적인 기능을 불러온다. (신경망 기술 등)\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Loss\n",
        "from sklearn.metrics import mean_squared_error # Regression 문제의 평가를 위해 MSE(Mean Squared Error)를 불러온다.\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt # 시각화 도구"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Too2dKCRvrkK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('reg.csv', index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GDTGsw8Vv0P6"
      },
      "outputs": [],
      "source": [
        "# 데이터를 넘파이 배열로 만들기\n",
        "X = df.drop('Price', axis=1).to_numpy() # 데이터프레임에서 타겟값(Price)을 제외하고 넘파이 배열로 만들기\n",
        "Y = df['Price'].to_numpy().reshape((-1,1)) # 데이터프레임 형태의 타겟값을 넘파이 배열로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-o0y7eLewlF3"
      },
      "outputs": [],
      "source": [
        "# 텐서 데이터로 변환하는 클래스(3강 참고)\n",
        "# trainset은 교차 검증을 위해 나누기 때문에 미리 DataLoader를 정의하지 않는다\n",
        "class TensorData(Dataset):\n",
        "\n",
        "    def __init__(self, x_data, y_data):\n",
        "        self.x_data = torch.FloatTensor(x_data)\n",
        "        self.y_data = torch.FloatTensor(y_data)\n",
        "        self.len = self.y_data.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QUjeMnMIwp8o"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.7)\n",
        "trainset = TensorData(X_train, Y_train)\n",
        "testset = TensorData(X_test, Y_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m-ZUAWOtw0yx"
      },
      "outputs": [],
      "source": [
        "# 모델 구축하기\n",
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 모델 연산 정의\n",
        "        self.fc1 = nn.Linear(13, 50, bias=True) # 입력층(13) -> 은닉층1(50)으로 가는 연산\n",
        "        self.fc2 = nn.Linear(50, 30, bias=True) # 은닉층1(50) -> 은닉층2(30)으로 가는 연산\n",
        "        self.fc3 = nn.Linear(30, 1, bias=True) # 은닉층2(30) -> 출력층(1)으로 가는 연산\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJbblWcAxM51"
      },
      "source": [
        "손실 함수와 교차 검증 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HY5QfSNzw4PC"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터를 3개의 폴드로 나누어 3겹 교차 검증을 진행한다\n",
        "kfold = KFold(n_splits=3, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mupm12PZw7vJ"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN7eBKi2ycYt"
      },
      "source": [
        "평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DR8wB_gRw_L8"
      },
      "outputs": [],
      "source": [
        "def evaluation(dataloader):\n",
        "\n",
        "    predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서\n",
        "    actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서\n",
        "\n",
        "    with torch.no_grad():  # 평가 시에는 모델 파라미터에 대한 업데이트 필요 X\n",
        "        model.eval() # 평가를 할 때에는 .eval() 반드시 사용해야 한다.\n",
        "        for data in dataloader:\n",
        "            inputs, values = data\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            predictions = torch.cat((predictions, outputs), 0) # cat을 통해 예측값을 누적\n",
        "            actual = torch.cat((actual, values), 0) # cat을 통해 실제값을 누적\n",
        "\n",
        "    predictions = predictions.numpy() # 넘파이 배열로 변경\n",
        "    actual = actual.numpy() # 넘파이 배열로 변경\n",
        "    rmse = np.sqrt(mean_squared_error(predictions, actual)) # sklearn을 이용하여 RMSE 계산 --> 성능 평가!!\n",
        "    model.train()\n",
        "    return rmse\n",
        "\n",
        "# 평가 시 .eval()을 사용해야 하는 이유\n",
        "# 이번 예시에서는 상관없으나 평가 시에는 정규화 기술을 배제하여 온전한 모델로 평가를 해야한다. 따라서 .eval()을 사용한다.\n",
        "# 즉, 드랍아웃이나 배치 정규화 등과 같이 학습 시에만 사용하는 기술들이 적용 된 모델은 평가 시에는 비활성화 해야하며 학습 시 .train()을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV1toxK4zUY9"
      },
      "source": [
        "교차 검증을 이용한 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ykAcJYJzWeu",
        "outputId": "987db442-a759-4eb3-9b86-1dd46a7998f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-fold 0 Train Loss: 0.0781, Validation Loss: 0.1347\n",
            "k-fold 1 Train Loss: 0.1090, Validation Loss: 0.0726\n",
            "k-fold 2 Train Loss: 0.1025, Validation Loss: 0.1190\n"
          ]
        }
      ],
      "source": [
        "validation_loss = []    # 검증 점수 산출 위해 폴드 별 손실 저장 리스트 제작\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(trainset)):     # 나눠진 학습 데이터의 인덱스 불러오기\n",
        "\n",
        "    # index 생성\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "     # sampler 이용하여 DataLoader 정의한\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, sampler=train_subsampler)\n",
        "    valloader = torch.utils.data.DataLoader(trainset, batch_size=32, sampler=val_subsampler)\n",
        "\n",
        "    # 모델\n",
        "    model = Regressor()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-7)\n",
        "\n",
        "    for epoch in range(400):    # 400번 학습 진행\n",
        "        for data in trainloader:  # 무작위로 섞인 32개 데이터가 있는 배치가 하나 씩 들어온다.\n",
        "            inputs, values = data   # data에는 X, Y가 들어있다\n",
        "            optimizer.zero_grad()   # 최적화 초기화\n",
        "\n",
        "            outputs = model(inputs) # 모델에 입력값 대입 후 예측값 산출\n",
        "            loss = criterion(outputs, values) # 손실 함수 계산\n",
        "            loss.backward() # 손실 함수 기준으로 역전파 설정\n",
        "            optimizer.step() # 역전파를 진행하고 가중치 업데이트\n",
        "\n",
        "    train_rmse = evaluation(trainloader)    # train 데이터의 RMSE 계산\n",
        "    val_rmse = evaluation(valloader)        # validation 데이터의 RMSE 계산\n",
        "    print(\"k-fold\", fold, \"Train Loss: %.4f, Validation Loss: %.4f\" %(train_rmse, val_rmse))\n",
        "    validation_loss.append(val_rmse)    # 검증 RMSE를 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "검증 점수 산출"
      ],
      "metadata": {
        "id": "oQbk-OStFYLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss = np.array(validation_loss)\n",
        "mean = np.mean(validation_loss)\n",
        "std = np.std(validation_loss)\n",
        "print(\"Validation Score: %.4f, ± %.4f\" %(mean, std))\n",
        "# 저장된 검증 RMSE의 평균과 표준편차 구한다!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWqF5eAuFeI6",
        "outputId": "46bcea44-64f8-4d56-91ef-75314d664007"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Score: 0.1088, ± 0.0264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "모델 평가하기\n",
        "\n"
      ],
      "metadata": {
        "id": "W7KgCPdnW5Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False)\n",
        "train_rmse = evaluation(trainloader) # 학습 데이터의 RMSE\n",
        "test_rmse = evaluation(testloader) # 시험 데이터의 RMSE\n",
        "\n",
        "print(\"Train RMSE: %.4f\" %train_rmse)\n",
        "print(\"Test RMSE: %.4f\" %test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvDdcg3fWv9S",
        "outputId": "8f88ca15-fb57-44c5-bfcc-e2614fe9d5de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 0.1083\n",
            "Test RMSE: 0.1343\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}